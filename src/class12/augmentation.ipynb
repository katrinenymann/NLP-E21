{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation using Augmentation\n",
    "For this class we will conduct model validation using augmentation, we will especially use the package [Augmenty](https://kennethenevoldsen.github.io/augmenty/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We will need to set up a few things before we start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages:\n",
    "For this tutorial you will need the following packages:\n",
    "\n",
    "- spaCy and augmenty are used for the augmentation\n",
    "- transformers are use to run the model we wish to validate\n",
    "- danlp is used to download the dataset we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: augmenty in /home/coder/.local/lib/python3.7/site-packages (0.0.9)\nRequirement already satisfied: spacy==3.1.1 in /home/coder/.local/lib/python3.7/site-packages (3.1.1)\nRequirement already satisfied: transformers==4.2.2 in /home/coder/.local/lib/python3.7/site-packages (4.2.2)\nRequirement already satisfied: danlp==0.0.12 in /home/coder/.local/lib/python3.7/site-packages (0.0.12)\nRequirement already satisfied: numpy>=1.15.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (1.19.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (2.24.0)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (3.10.0.2)\nRequirement already satisfied: typer<0.4.0,>=0.3.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (0.3.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (2.0.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (3.0.8)\nRequirement already satisfied: packaging>=20.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (20.4)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (4.49.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (0.8.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (2.0.6)\nRequirement already satisfied: pathy>=0.3.5 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (0.6.1)\nRequirement already satisfied: jinja2 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (2.11.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (3.0.6)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (0.7.5)\nRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy==3.1.1) (40.8.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (2.4.2)\nRequirement already satisfied: thinc<8.1.0,>=8.0.8 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (8.0.13)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (1.8.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy==3.1.1) (1.0.6)\nRequirement already satisfied: sacremoses in /home/coder/.local/lib/python3.7/site-packages (from transformers==4.2.2) (0.0.46)\nRequirement already satisfied: filelock in /home/coder/.local/lib/python3.7/site-packages (from transformers==4.2.2) (3.4.0)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/coder/.local/lib/python3.7/site-packages (from transformers==4.2.2) (1.7.0)\nRequirement already satisfied: tokenizers==0.9.4 in /home/coder/.local/lib/python3.7/site-packages (from transformers==4.2.2) (0.9.4)\nRequirement already satisfied: regex!=2019.12.17 in /home/coder/.local/lib/python3.7/site-packages (from transformers==4.2.2) (2021.11.10)\nRequirement already satisfied: pyconll in /home/coder/.local/lib/python3.7/site-packages (from danlp==0.0.12) (3.1.0)\nRequirement already satisfied: pandas in /home/coder/.local/lib/python3.7/site-packages (from danlp==0.0.12) (1.1.2)\nRequirement already satisfied: tweepy in /home/coder/.local/lib/python3.7/site-packages (from danlp==0.0.12) (4.4.0)\nRequirement already satisfied: conllu in /home/coder/.local/lib/python3.7/site-packages (from danlp==0.0.12) (4.4.1)\nRequirement already satisfied: idna<3,>=2.5 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (1.25.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (2020.6.20)\nRequirement already satisfied: click<7.2.0,>=7.1.1 in /home/coder/.local/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy==3.1.1) (7.1.2)\nRequirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /home/coder/.local/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.4->spacy==3.1.1) (3.1.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from packaging>=20.0->spacy==3.1.1) (1.12.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /home/coder/.local/lib/python3.7/site-packages (from packaging>=20.0->spacy==3.1.1) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/coder/.local/lib/python3.7/site-packages (from pathy>=0.3.5->spacy==3.1.1) (5.2.1)\nRequirement already satisfied: MarkupSafe>=0.23 in /home/coder/.local/lib/python3.7/site-packages (from jinja2->spacy==3.1.1) (1.1.1)\nRequirement already satisfied: joblib in /home/coder/.local/lib/python3.7/site-packages (from sacremoses->transformers==4.2.2) (0.16.0)\nRequirement already satisfied: pytz>=2017.2 in /home/coder/.local/lib/python3.7/site-packages (from pandas->danlp==0.0.12) (2020.1)\nRequirement already satisfied: python-dateutil>=2.7.3 in /home/coder/.local/lib/python3.7/site-packages (from pandas->danlp==0.0.12) (2.8.1)\nRequirement already satisfied: requests-oauthlib<2,>=1.0.0 in /home/coder/.local/lib/python3.7/site-packages (from tweepy->danlp==0.0.12) (1.3.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/coder/.local/lib/python3.7/site-packages (from requests-oauthlib<2,>=1.0.0->tweepy->danlp==0.0.12) (3.1.1)\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: da-core-news-lg==3.1.0 from https://github.com/explosion/spacy-models/releases/download/da_core_news_lg-3.1.0/da_core_news_lg-3.1.0-py3-none-any.whl#egg=da_core_news_lg==3.1.0 in /home/coder/.local/lib/python3.7/site-packages (3.1.0)\nRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /home/coder/.local/lib/python3.7/site-packages (from da-core-news-lg==3.1.0) (3.1.1)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.0.6)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (4.49.0)\nRequirement already satisfied: packaging>=20.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (20.4)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (0.7.5)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.4.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (3.0.6)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (0.8.2)\nRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (40.8.0)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.0.6)\nRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (3.10.0.2)\nRequirement already satisfied: typer<0.4.0,>=0.3.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (0.3.2)\nRequirement already satisfied: pathy>=0.3.5 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (0.6.1)\nRequirement already satisfied: numpy>=1.15.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.19.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (3.0.8)\nRequirement already satisfied: jinja2 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.11.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.24.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.8.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.0.6)\nRequirement already satisfied: thinc<8.1.0,>=8.0.8 in /home/coder/.local/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (8.0.13)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.12.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /home/coder/.local/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.4.7)\nRequirement already satisfied: click<7.2.0,>=7.1.1 in /home/coder/.local/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (7.1.2)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/coder/.local/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (5.2.1)\nRequirement already satisfied: MarkupSafe>=0.23 in /home/coder/.local/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.1.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/coder/.local/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (1.25.10)\nRequirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /home/coder/.local/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->da-core-news-lg==3.1.0) (3.1.0)\n\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('da_core_news_lg')\n"
    }
   ],
   "source": [
    "!pip install augmenty spacy==3.1.1 transformers==4.2.2 danlp==0.0.12\n",
    "!python -m spacy download da_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "For this dataset we will be using [DKHate](https://github.com/alexandrainst/danlp/blob/master/docs/docs/datasets.md#dkhate). The DKHate dataset contains user-generated comments from social media platforms (Facebook and Reddit) annotated for various types and target of offensive language. Note that only labels for the sub-task A (Offensive language identification), i.e. NOT (Not Offensive) / OFF (Offensive), are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from danlp.datasets import DKHate\n",
    "import pandas as pd\n",
    "dkhate = DKHate()\n",
    "test, train = dkhate.load_with_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make everything run faster we will only be using a subsample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 20\n",
    "\n",
    "# make sure to sample evenly from the two samples\n",
    "n_labels = len(test[\"subtask_a\"].unique())\n",
    "samples_pr_lab = samples//n_labels\n",
    "\n",
    "off = test[test[\"subtask_a\"] == \"OFF\"].sample(samples_pr_lab)\n",
    "not_off = test[test[\"subtask_a\"] == \"NOT\"].sample(samples_pr_lab)\n",
    "mini_test = pd.concat([off, not_off])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the data using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  tweet subtask_a\nid                                                               \n753   uuh, denne her bliver nok upopulær, men jeg er...       OFF\n546   Norge er nu ikke så slemt igen... AKA Svensken...       OFF\n9     Hvordan i helvede fik de overhovedet dit numme...       OFF\n890   Syge kælling, hun skulle i fængsel for det stu...       OFF\n1695                                  NED MED SVENSKEN!       OFF\n1546  Og så er det oven i købet vores nationalfugl. ...       OFF\n137                            @USER ryger du hash. ???       OFF\n430                 Hva fanden er der galt med folk??!!       OFF\n962   Passiv aggressiv måde at kalde dig for et pikfjæs       OFF\n3397                      Hold nu kæft det er grineren!       OFF\n927                Håber der er Fodbold på den tid i TV       NOT\n777   Jeg mener ikke at en mand er mere troværdig. J...       NOT\n3398                            ER DET ARABISK YOGHURT?       NOT\n3012  Dit dansk er okay, @USER. Hvad var du landet f...       NOT\n1558  I ved hvem de er så tving dem til at rydde op ...       NOT\n2799  Hvor mange hurtigere alternativer var der deng...       NOT\n2111  Meget sjovt, men forstår ikke det der 'of' ove...       NOT\n2373  Et flag så godt at selv svensken måtte kopiere...       NOT\n2895  Gad vide om hans næste arbejde bliver McKinsey...       NOT\n678   De skal sendes retur hele bundtet vi har ikke ...       NOT",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>753</th>\n      <td>uuh, denne her bliver nok upopulær, men jeg er...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>Norge er nu ikke så slemt igen... AKA Svensken...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hvordan i helvede fik de overhovedet dit numme...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>Syge kælling, hun skulle i fængsel for det stu...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>NED MED SVENSKEN!</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>1546</th>\n      <td>Og så er det oven i købet vores nationalfugl. ...</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>@USER ryger du hash. ???</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>Hva fanden er der galt med folk??!!</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>962</th>\n      <td>Passiv aggressiv måde at kalde dig for et pikfjæs</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>3397</th>\n      <td>Hold nu kæft det er grineren!</td>\n      <td>OFF</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>Håber der er Fodbold på den tid i TV</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>777</th>\n      <td>Jeg mener ikke at en mand er mere troværdig. J...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3398</th>\n      <td>ER DET ARABISK YOGHURT?</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>3012</th>\n      <td>Dit dansk er okay, @USER. Hvad var du landet f...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>1558</th>\n      <td>I ved hvem de er så tving dem til at rydde op ...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2799</th>\n      <td>Hvor mange hurtigere alternativer var der deng...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2111</th>\n      <td>Meget sjovt, men forstår ikke det der 'of' ove...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2373</th>\n      <td>Et flag så godt at selv svensken måtte kopiere...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>2895</th>\n      <td>Gad vide om hans næste arbejde bliver McKinsey...</td>\n      <td>NOT</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>De skal sendes retur hele bundtet vi har ikke ...</td>\n      <td>NOT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "mini_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "For this dataset we will be using a model trained on the train set of the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"DaNLP/da-bert-hatespeech-detection\"\n",
    "pipe = pipeline(\"sentiment-analysis\", # text classification == sentiment analysis (don't ask me why, but they removed textcat in the latest version)\n",
    "               model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly check the output using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'label': 'offensive', 'score': 0.9902199506759644},\n {'label': 'not offensive', 'score': 0.9998297691345215}]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "pipe([\"Gamle stupide idiot\", \"Lækkert vejr i dag\"]) # old stupid idiot, nice weather today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly apply this model to all our examples and save them in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = mini_test[\"tweet\"].to_list()\n",
    "\n",
    "def apply(texts):\n",
    "    output = pipe(texts, truncation=True)\n",
    "    return [t[\"score\"] if t[\"label\"] == \"offensive\" else 1 - t[\"score\"] for t in output]\n",
    "\n",
    "\n",
    "# first without augmentations\n",
    "mini_test[\"p_offensive_no_aug\"] = apply(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural check using Augmentation\n",
    "\n",
    "In the following we want to examine the behavioural consistency of the model using augmentation. The idea is to check the behavioural consistently of the model for instance if we introduce slight spelling errors we the model should still be able to recognize names. If this is not the case it might be unwise to apply the model to domains where spelling errors are common such as social media.  \n",
    "\n",
    "![](img/aug.png)\n",
    "**Figure 1**: Examples of augmentation applied by Enevoldsen et al. (2020) and what domains they might be of relevance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenty\n",
    "For the augmentation we will be using the package augmenty, the following provides a brief introduction to it.\n",
    "\n",
    "**NOTE**: You are naturally not forced to use augmenty, you implement your own augmenters i.e. the following example with uppercasing is easy to implement by hand.  For example if you want to examine the effect of questionmarks you could make the augmentation:\n",
    "```py\n",
    "q_aug = [text + \"?\" for text in texts]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "spacy.orth_variants.v1\nspacy.lower_case.v1\nrandom_casing.v1\nchar_replace_random.v1\nchar_replace.v1\nkeystroke_error.v1\nremove_spacing.v1\nchar_swap.v1\nrandom_starting_case.v1\nconditional_token_casing.v1\ntoken_dict_replace.v1\nwordnet_synonym.v1\ntoken_replace.v1\nword_embedding.v1\ngrundtvigian_spacing_augmenter.v1\nspacing_insertion.v1\ntoken_swap.v1\ntoken_insert.v1\ntoken_insert_random.v1\nduplicate_token.v1\nrandom_synonym_insertion.v1\nents_replace.v1\nper_replace.v1\nents_format.v1\nupper_case.v1\nspongebob.v1\nda_æøå_replace.v1\nda_historical_noun_casing.v1\n"
    }
   ],
   "source": [
    "import augmenty\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_lg\")\n",
    "\n",
    "# a list of augmenters\n",
    "for augmenter in augmenty.augmenters():\n",
    "    print(augmenter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list naturally does not give you all the information you need. You can always examine a specific augmenter more en detain in the [documentation](https://kennethenevoldsen.github.io/augmenty/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try one of the augmenters. We can use the `augmenty.load` as a common interface for all augmenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an augmenter\n",
    "upper_case_augmenter = augmenty.load(\"upper_case.v1\", level=1.00) # augment 100% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These augmenters are made to work on the SpaCy data class Examples which allows for much more detailed augmentation, however augmenty have utility function to allow us to use them for strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['THIS IS AN EXAMPLE', 'AND ANOTHER ONE']"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "examples = [\"this is an example\", \"and another one\"]\n",
    "aug_texts = augmenty.texts(examples, augmenter=upper_case_augmenter, nlp=nlp)\n",
    "list(aug_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is uppercasing more offensive?\n",
    "\n",
    "Now we will can apply our model to the augmented examples to see if it changes predictions of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_texts = augmenty.texts(texts, augmenter=upper_case_augmenter, nlp=nlp)\n",
    "mini_test[\"p_offensive_upper\"] = apply(list(aug_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the output of our models we quickly see that it doesn't change the result at all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  tweet subtask_a  \\\nid                                                                  \n1546  Og så er det oven i købet vores nationalfugl. ...       OFF   \n1251  Han EJER ikke respekt for nogen eller noget......       OFF   \n209   Ja løget mindst om, ud af alle de ting der bli...       OFF   \n1818                     ##FUCK JA! DANMARK LÆNGE LEVE!       OFF   \n546   Norge er nu ikke så slemt igen... AKA Svensken...       OFF   \n701   @USER hvis hun ikke kan koge pastaen rigtigt, ...       OFF   \n3545  Potentiale til månedens billede, lige der.  De...       OFF   \n753   uuh, denne her bliver nok upopulær, men jeg er...       OFF   \n2542                                        DANSKJÄVLAR       OFF   \n519   Det sgu heller ikke okay. jeg havde sgu også b...       OFF   \n757   Er folk blevet fuldstændig vanvittige ??? Man ...       NOT   \n2493  GÅR UD FRA DEN GUD DE OMTALER ER HOLGER DANSKE...       NOT   \n633   Og hvad med Danelagen? St. Croix, St. Thomas o...       NOT   \n1143  mon ikke han ligger i graven om 50 + år... det...       NOT   \n1330  Og det var Danmagg og det var Danmaaaag Ole ol...       NOT   \n2245                                        Der hjemme.       NOT   \n1944  Jeg tror ikke at /r/Polandball/ synes godt om,...       NOT   \n3221                                                Lol       NOT   \n2627                                                lol       NOT   \n1439             SÅ VACKERT SÅ ATT JAG GRÅTER ÄLGTÅRAR!       NOT   \n\n      p_offensive_no_aug  p_offensive_upper  \nid                                           \n1546            0.858211           0.858211  \n1251            0.978986           0.978986  \n209             0.977304           0.977304  \n1818            0.000488           0.000488  \n546             0.001790           0.001790  \n701             0.973846           0.973846  \n3545            0.001631           0.001631  \n753             0.021918           0.021918  \n2542            0.062679           0.062679  \n519             0.000431           0.000431  \n757             0.064492           0.064492  \n2493            0.030394           0.030394  \n633             0.000229           0.000229  \n1143            0.003635           0.003635  \n1330            0.001907           0.001907  \n2245            0.000687           0.000687  \n1944            0.001196           0.001196  \n3221            0.000281           0.000281  \n2627            0.000281           0.000281  \n1439            0.022519           0.022519  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>p_offensive_no_aug</th>\n      <th>p_offensive_upper</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1546</th>\n      <td>Og så er det oven i købet vores nationalfugl. ...</td>\n      <td>OFF</td>\n      <td>0.858211</td>\n      <td>0.858211</td>\n    </tr>\n    <tr>\n      <th>1251</th>\n      <td>Han EJER ikke respekt for nogen eller noget......</td>\n      <td>OFF</td>\n      <td>0.978986</td>\n      <td>0.978986</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>Ja løget mindst om, ud af alle de ting der bli...</td>\n      <td>OFF</td>\n      <td>0.977304</td>\n      <td>0.977304</td>\n    </tr>\n    <tr>\n      <th>1818</th>\n      <td>##FUCK JA! DANMARK LÆNGE LEVE!</td>\n      <td>OFF</td>\n      <td>0.000488</td>\n      <td>0.000488</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>Norge er nu ikke så slemt igen... AKA Svensken...</td>\n      <td>OFF</td>\n      <td>0.001790</td>\n      <td>0.001790</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>@USER hvis hun ikke kan koge pastaen rigtigt, ...</td>\n      <td>OFF</td>\n      <td>0.973846</td>\n      <td>0.973846</td>\n    </tr>\n    <tr>\n      <th>3545</th>\n      <td>Potentiale til månedens billede, lige der.  De...</td>\n      <td>OFF</td>\n      <td>0.001631</td>\n      <td>0.001631</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>uuh, denne her bliver nok upopulær, men jeg er...</td>\n      <td>OFF</td>\n      <td>0.021918</td>\n      <td>0.021918</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>DANSKJÄVLAR</td>\n      <td>OFF</td>\n      <td>0.062679</td>\n      <td>0.062679</td>\n    </tr>\n    <tr>\n      <th>519</th>\n      <td>Det sgu heller ikke okay. jeg havde sgu også b...</td>\n      <td>OFF</td>\n      <td>0.000431</td>\n      <td>0.000431</td>\n    </tr>\n    <tr>\n      <th>757</th>\n      <td>Er folk blevet fuldstændig vanvittige ??? Man ...</td>\n      <td>NOT</td>\n      <td>0.064492</td>\n      <td>0.064492</td>\n    </tr>\n    <tr>\n      <th>2493</th>\n      <td>GÅR UD FRA DEN GUD DE OMTALER ER HOLGER DANSKE...</td>\n      <td>NOT</td>\n      <td>0.030394</td>\n      <td>0.030394</td>\n    </tr>\n    <tr>\n      <th>633</th>\n      <td>Og hvad med Danelagen? St. Croix, St. Thomas o...</td>\n      <td>NOT</td>\n      <td>0.000229</td>\n      <td>0.000229</td>\n    </tr>\n    <tr>\n      <th>1143</th>\n      <td>mon ikke han ligger i graven om 50 + år... det...</td>\n      <td>NOT</td>\n      <td>0.003635</td>\n      <td>0.003635</td>\n    </tr>\n    <tr>\n      <th>1330</th>\n      <td>Og det var Danmagg og det var Danmaaaag Ole ol...</td>\n      <td>NOT</td>\n      <td>0.001907</td>\n      <td>0.001907</td>\n    </tr>\n    <tr>\n      <th>2245</th>\n      <td>Der hjemme.</td>\n      <td>NOT</td>\n      <td>0.000687</td>\n      <td>0.000687</td>\n    </tr>\n    <tr>\n      <th>1944</th>\n      <td>Jeg tror ikke at /r/Polandball/ synes godt om,...</td>\n      <td>NOT</td>\n      <td>0.001196</td>\n      <td>0.001196</td>\n    </tr>\n    <tr>\n      <th>3221</th>\n      <td>Lol</td>\n      <td>NOT</td>\n      <td>0.000281</td>\n      <td>0.000281</td>\n    </tr>\n    <tr>\n      <th>2627</th>\n      <td>lol</td>\n      <td>NOT</td>\n      <td>0.000281</td>\n      <td>0.000281</td>\n    </tr>\n    <tr>\n      <th>1439</th>\n      <td>SÅ VACKERT SÅ ATT JAG GRÅTER ÄLGTÅRAR!</td>\n      <td>NOT</td>\n      <td>0.022519</td>\n      <td>0.022519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "mini_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be a bit more explicit we can also compare it using summary information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The augmentation lead to classification changes in 0/20\nThe average prob. of OFF went from 0.497(0.488) to 0.497(0.488).\nThe average prob. of NOT went from 0.094(0.281) to 0.094(0.281).\n"
    }
   ],
   "source": [
    "def compare_cols(\n",
    "    augmentation,\n",
    "    baseline=mini_test[\"p_offensive_no_aug\"],\n",
    "    category=mini_test[\"subtask_a\"],\n",
    "):\n",
    "    \"\"\"Compares augmentation with the baseline for each of the categories\"\"\"\n",
    "    changes = ((augmentation > 0.5) != (baseline > 0.5)).sum()\n",
    "    n = len(augmentation)\n",
    "    print(f\"The augmentation lead to classification changes in {changes}/{n}\")\n",
    "    for cat in set(category):\n",
    "        aug_cat_mean = augmentation[category == cat].mean().round(3)\n",
    "        aug_cat_std = augmentation[category == cat].std().round(3)\n",
    "        cat_mean = baseline[category == cat].mean().round(3)\n",
    "        cat_std = baseline[category == cat].std().round(3)\n",
    "        print(\n",
    "            f\"The average prob. of {cat} went from {cat_mean}({cat_std}) to {aug_cat_mean}({aug_cat_std}).\"\n",
    "        )\n",
    "\n",
    "compare_cols(mini_test[\"p_offensive_upper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "\n",
    "1) Solve the above mystery, why doesn't the model estimate change might when uppercasing? *Hint*: Check the tokenizer of the model\n",
    "\n",
    "It must be because the tokenizer does not look at lower vs. upper case but can't find it. \n",
    "\n",
    "2) Examining the data, I seemed to notice that spelling error were more common among offensive tweets. Is this correct? [*Hint*](https://kennethenevoldsen.github.io/augmenty/augmenty.character.html?highlight=keystroke#augmenty.character.replace.create_keystroke_error_augmenter)\n",
    "\n",
    "3) Examine the data yourself and create three hypothesis on what augmentation might change the performance.\n",
    "Changing male vs. female names. \n",
    "\n",
    "4) Outline how you could apply augmentation (behavioral testing) to examine a model (or pipeline) in your project\n",
    "\n",
    "Could be female vs. male names. \n",
    "\n",
    "5) (Optional): Apply this behavioural testing to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['uuh, denb4 her blkver nok upooulæd, men jeg er sgu lidt enig.  jojk, jokes er jokes... men hvis du l<ved fn jokd om nogdn, om det er en enkfltpeeson eller ek f0lkegruppe, 9g den eller dem jok2n er møntet åå sig3r “hey, ddt synes jeg daktiwk okke er så f2dt, swlvo, det baee er en joke, vulls du ikke lzde være?” og *du* føler dig krænket og uforrettet, så e4 det altså dig der er r¨vhulket i dén sag.  lav nu ga3e jer3s jokes, men lad ju v,r at jlive fornægmede jår d9ll ikke synss de er sjove. begte sidef ffemstår cirka lige hys i debatten.', \"Norge er ju ikke så slemt igen... AKA Svensken ain't rot sh8t on us..l\", 'Hvordan i helfede dii ze overhovedet dit kummer!Å Klamme spionland.', 'Syge mælling, vun skukle i cængsel fpr det stunt. ', 'NED MED SVENSKEN!', 'Og så er det oven i købet væres nationalfugl.  Hvad er svejskernes? En fucking solsort.  Nyd jeres kolonihave-musvit, snus-tobau gnaskere!', '@(SER rjger d8 hash. ?^?', 'Hva fqnden er xer galt med foik??!!', 'Passiv aggrfssiv nådr at kalde dig for et pokfkæs', 'Hild nu kæft det er grinerej!', 'Håber fer er Fodbold på dek tid i TV', 'Neg kensr ikke ah en mand er mere trohærdig. Jeg ioks5ate5e blot det faktum at vi lever i en tid, hvor en kv8nde kan quge hgad som helst og ordensmagten hopper i med begge ben. Heg sigwr ikke at det sker hver gang, mem det sker for mange gange.', 'ER DET ARAVISK /OGVIRT?', 'Dit dwnsk er okay, @USER. Hvad var du landet for 4il at srartf med?', 'I ved nvem de er så tvinh dfm til at r7dde op og erstatte alt gvad de har ødelagt dllers må forældre betake .Det yngel tar 7kk3 mrgdr hjerne ,keg rr sikker på at dkatte ydern3 4d trætte af at betale for alt den hærværk ', 'Hvor mange hurtigere alt4rnativer faf set cengang?', \"Megr5 sjovt, m2n forstår ikke det der 'of' 8ve5alt - gør vi dey?\", 'Ey flag zå godt a6 selv svensken måtte klpiere de5.', 'Gad bodr om hsns næste arbejde bliver LcKinsey, eller McKinzey', 'De skai sended retur hele bundter vi har ikke bg6g coe rlere udgifter i det danske samfund']\n"
    }
   ],
   "source": [
    "#2)\n",
    "key_stroke_error = augmenty.load(\"keystroke_error.v1\", level =0.1, keyboard = \"da_qwerty.v1\")\n",
    "examples = [\"hello you are very sweer\", \"hello you are very stupid\"]\n",
    "#aug_texts = augmenty.texts(examples, augmenter = key_stroke_error, nlp = nlp)\n",
    "\n",
    "text_list = list(augmenty.texts(texts, key_stroke_error, nlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The augmentation lead to classification changes in 3/20\nThe average prob. of OFF went from 0.497(0.488) to 0.179(0.341).\nThe average prob. of NOT went from 0.094(0.281) to 0.096(0.296).\n"
    }
   ],
   "source": [
    "mini_test[\"test\"] = apply(list(text_list))\n",
    "compare_cols(mini_test[\"test\"]) "
   ]
  },
  {
   "source": [
    "Three were classified differently via this augmentation. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "021482b7625aaacc2d343324781c6ce2f121934a239bde69eda2b56fdffea080"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit107f740f4d6d4413ac7f7197d95903b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}